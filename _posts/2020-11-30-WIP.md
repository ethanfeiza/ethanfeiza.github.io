---
title: "SQL & Tableau: Chat Room Data Analysis"
date: 2020-12-01
tags: [SQL, Tableau, Python, Data Analysis]
excerpt: "Upload in progress..."
---

## Background
Kooth is a free online mental health service for individuals aged 11-25 years old. Service users can access an online chatroom feature allowing them to speak with trained mental health counselers. 

Kooth has provided two datasets containing information on service user activity within this chatroom feature. This data was collected during the week of April 13th, 2020. All service users in this data are located within the United States. 

We have been asked to investigate trends in service user behavior regarding chat attempts, wait times, and successful chats from queues. First, we will use SQL and Python to join and format the two datasets. After that, we will visualize our findings in Tableau with interactive dashboards. All Python code will be executed in an IPython kernel using Jupyter Notebook.

**Key Notes**

- 'Queues' are synonymous for waits to enter a Kooth chatroom.
- Not all successful chats require queues. Users can book chat appointments ahead of time.
- Not all users have a successful chat after initiating a queue.
- Users can be removed from their queues by a practitioner if they are not going to get a chat. They may also exit queues themselves.

## Data Analysis
For this analysis, we will be executing MySQL queries within a Python environment using the *pandasql* Python package. Before we begin, we must install this package on our desktop. We can then import all required packages for analysis.

```python
# install pandasql on desktop
pip install pandasql

# import required libraries
from pandasql import sqldf
import pandas as pd
```

Next, we will initialize a SQL querying function in Python. This can be done using a simple lambda function.

```python
# initialize SQL querying function
pysql = lambda q: sqldf(q, globals())
```

We will now import the Kooth datasets as pandas dataframes. We will also rename the variables in both datasets for better clarity.

```python
# import Kooth datasets
queue_df = pd.read_csv("C:/Users/ethan/OneDrive/Documents/Kooth/join_queue_events.csv")
chat_df = pd.read_csv("C:/Users/ethan/OneDrive/Documents/Kooth/chat_start_events.csv")

# assign new variable names
queue_df = queue_df.rename(columns = {
    'Service User ID':'user_id', 
    'Join Queue Event ID':'queue_id',
    'date_su join queue':'queue_start',
    'date_su left queue':'queue_end'}
)

chat_df = chat_df.rename(columns = {
    'Service User ID':'user_id', 
    'chats starts':'chat_start',
    'chat ends':'chat_end',
    'meeting room ID':'meeting_room_id'}
)
```

**queue_df** contains four variables:

- *user_id* indicates the unique ID assigned to each Kooth service user.
- *queue_id* represents an ID for each distinct queue initialized by a user.
- *queue_start* represents the datetime of an initialized queue.
- *queue_end* represents the datetime of a terminated queue.

**chat_df** contains four variables:

- *user_id* indicates the unique ID assigned to each Kooth service user.
- *chat_start* represents the datetime of an initialized chat.
- *chat_end* represents the datetime of a terminated chat.
- *meeting_room_id* indicates the unique ID generated for each distinct chat session.

We can see that *user_id* is a shared variable in both dataframes. Before we join this data togther, we will perform a simple deduplication of rows in each dataframe using SQL.

```python
# 0 rows were removed from queue_df
queue_df = sqldf(
'''
SELECT distinct *
FROM queue_df
'''
)

# 1383 duplicate rows were removed from chat_df
chat_df = sqldf(
'''
SELECT distinct *
FROM chat_df
'''
)
```

When considering the Kooth chatroom feature, we can place service users into one of three bins.

1.) Users who queued and failed to chat.
{:start="2"}
2.) Users who queued and chatted successfully.
3.) Users who did not queue and chatted successfully.




