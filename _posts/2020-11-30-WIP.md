---
title: "SQL & Tableau: Chat Room Data Analysis"
date: 2020-12-01
tags: [SQL, Tableau, Python, Data Analysis]
excerpt: "Upload in progress..."
---

## Background
Kooth is a free online mental health service for individuals aged 11-25 years old. Service users can access an online chatroom feature allowing them to speak with trained mental health counselers. 

Kooth has provided two datasets containing information on service user activity within this chatroom feature. This data was collected during the week of April 13th, 2020. All service users in this data are located within the United States. 

We have been asked to investigate trends in service user behavior regarding chat attempts, wait times, and successful chats from queues. First, we will use SQL and Python to join and format the two datasets. After that, we will visualize our findings in Tableau with interactive dashboards. All Python code will be executed in an IPython kernel using Jupyter Notebook.

**Key Notes**

- 'Queues' are synonymous for waits to enter a Kooth chatroom.
- Not all successful chats require queues. Users can book chat appointments ahead of time.
- Not all users have a successful chat after initiating a queue.
- Users can be removed from their queues by a practitioner if they are not going to get a chat. They may also exit queues themselves.

## Data Analysis
For this analysis, we will be executing MySQL queries within a Python environment using the *pandasql* Python package. Before we begin, we must install this package on our desktop. We can then import all required packages for analysis.

```python
# install pandasql on desktop
pip install pandasql

# import required libraries
from pandasql import sqldf
import pandas as pd
```

Next, we will initialize a SQL querying function in Python. This can be done using a simple lambda function.

```python
# initialize SQL querying function
pysql = lambda q: sqldf(q, globals())
```

We will now import the Kooth datasets as pandas dataframes. We will also rename the variables in both datasets for better clarity.

```python
# import Kooth datasets
queue_df = pd.read_csv("C:/Users/ethan/OneDrive/Documents/Kooth/join_queue_events.csv")
chat_df = pd.read_csv("C:/Users/ethan/OneDrive/Documents/Kooth/chat_start_events.csv")

# assign new variable names
queue_df = queue_df.rename(columns = {
    'Service User ID':'user_id', 
    'Join Queue Event ID':'queue_id',
    'date_su join queue':'queue_start',
    'date_su left queue':'queue_end'}
)

chat_df = chat_df.rename(columns = {
    'Service User ID':'user_id', 
    'chats starts':'chat_start',
    'chat ends':'chat_end',
    'meeting room ID':'meeting_room_id'}
)
```

**queue_df** contains four variables:

- *user_id* indicates the unique ID assigned to each Kooth service user.
- *queue_id* represents an ID for each distinct queue initialized by a user.
- *queue_start* represents the datetime of an initialized queue.
- *queue_end* represents the datetime of a terminated queue.

**chat_df** contains four variables:

- *user_id* indicates the unique ID assigned to each Kooth service user.
- *chat_start* represents the datetime of an initialized chat.
- *chat_end* represents the datetime of a terminated chat.
- *meeting_room_id* indicates the unique ID generated for each distinct chat session.

We can see that *user_id* is a shared variable in both dataframes. Before we join this data togther, we will perform a simple deduplication of rows in each dataframe using SQL.

```python
# 0 rows were removed from queue_df
queue_df = sqldf(
'''
SELECT distinct *
FROM queue_df
'''
)

# 1383 duplicate rows were removed from chat_df
chat_df = sqldf(
'''
SELECT distinct *
FROM chat_df
'''
)
```

When considering the Kooth chatroom feature, service users belong to one of three scenarios:

1. Users who queued and failed to chat.
1. Users who queued and chatted successfully.
1. Users who did not queue and chatted successfully.

We will filter and join data from *queue_df* and *chat_df* by creating distinct tables for each of these three scenarios. After creating these tables, we will combine them to create a master dataset that can be imported into Tableau for further analysis.

Starting with ***scenario 1***, we will create a table for user records that initiated a queue but failed to chat. While exploring this data, we found that some users had instantiated multiple queues ending at the same time. This could be the due to errors in the user-data logging system, or perhaps the result of a user opening multiple queues on different tabs of their browser.

Regardless of the cause for this discrepancy, we will only keep the record with the longest queue duration per queue cluster. These types of records will best reflect the true wait time of each user after starting a queue for a distinct chat session.

Using SQL, we will first create a common table expression *RankedQueues* that left-joins *user_id* from *chat_df* onto *queue_df*. Within *RankedQueues*, we will construct a field *row_num* using a window funciton to partition by users with queues ending at the same time. Within each aforementioned queue cluster, we will rank records by queue start time to indicate the longest (most accurate) queue duration for that distinct queue session.

```python
# create a table for records with queues that failed to chat
queue_fail = sqldf(
'''
WITH RankedQueues AS (
    SELECT
        q.*,
        ROW_NUMBER() OVER (PARTITION BY q.user_id, q.queue_end ORDER BY q.queue_start) AS row_num,
        c.chat_start,
        c.chat_end,
        c.meeting_room_id
    FROM
        queue_df q
    LEFT JOIN
        chat_df c ON q.user_id = c.user_id
)

SELECT
    user_id,
    queue_id,
    queue_start,
    queue_end,
    ROUND((1.0 * (strftime('%s', substr(queue_end, 7, 4) || '-' || substr(queue_end, 4, 2) || '-' || substr(queue_end, 1, 2) || ' ' || substr(queue_end, 12))) - strftime('%s', substr(queue_start, 7, 4) || '-' || substr(queue_start, 4, 2) || '-' || substr(queue_start, 1, 2) || ' ' || substr(queue_start, 12))) / 60.0, 2) AS queue_minutes,
    chat_start,
    chat_end,
    ROUND((1.0 * (strftime('%s', substr(chat_end, 7, 4) || '-' || substr(chat_end, 4, 2) || '-' || substr(chat_end, 1, 2) || ' ' || substr(chat_end, 12))) - strftime('%s', substr(chat_start, 7, 4) || '-' || substr(chat_start, 4, 2) || '-' || substr(chat_start, 1, 2) || ' ' || substr(chat_start, 12))) / 60.0, 2) AS chat_minutes,
    meeting_room_id
FROM
    RankedQueues
WHERE
    row_num = 1 AND chat_start IS NULL
ORDER BY
    user_id, queue_end
'''
)
```

Now, we can display the first 5 rows of *queue_fail*.

```python
queue_fail.head()
```

| user_id |	queue_id |	queue_start| 	queue_end |	queue_minutes |	chat_start | chat_end	| chat_minutes |	meeting_room_id |
| --- | --: | --: | --: | --: | --: | --: | --: | --: |
| 0015d01f-f8f1-4f8a-9c33-c22b45b3e59a | d6b735f4-dd34-4e1b-aa1b-0c6d1f84ef45 | 17/04/2020 11:23:02	| 17/04/2020 11:56:29 | 33.45 | None | None	| None | None |
| 0070a3e7-fee7-48f8-82d7-af96b1d08082 | bc49da27-124f-410b-a97f-6dc36ac520ff | 17/04/2020 16:03:40	| 17/04/2020 16:03:57 | 0.28 | None	| None | None | None |
| 007e63d9-51e0-4738-89d1-ba968cfa9820 | 1c45e072-284b-4145-b65e-91363ca7c7c6 | 15/04/2020 13:44:49	| 15/04/2020 13:49:26 | 4.62 | None	| None | None | None |
| 007e63d9-51e0-4738-89d1-ba968cfa9820 | b4533ead-0cb9-4f44-bb5f-01e3bc74032e | 15/04/2020 14:14:51	| 15/04/2020 14:15:46 | 0.92 | None	| None	| None | None |
| 0086373e-4c0b-4c2a-b82e-9f3057f14de4 | 01bcf559-9928-4dbb-900a-35a73e4716e9 | 17/04/2020 19:57:50	| 17/04/2020 19:59:51 | 2.02 | None	| None	| None | None |







