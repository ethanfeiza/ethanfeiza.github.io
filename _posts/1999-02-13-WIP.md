---
title: "WIP... Exploring Markov Chains"
date: 1999-02-13
tags: [Stochastic Modeling, Linear Algebra, Python]
excerpt: "Explore the Therory of Markov Chains in Stochastic Modeling"
---

## Background
When creating a discrete predictive model, intuition may sometimes lead us to believe that more features equals stronger results. A powerful neural network, for example, may use an extensive feature set and deep internal history to predict a desired output with precision. However, this is not always necessary to achieve accuracy.

A *stochastic process* involves transitions between states determined by probability. In such a process, the following property holds: the future depends only on the present, not on how we arrived there. This principle, known as the Markov property, underlies one of the most elegant frameworks in probabilistic modeling.

A *Markov Chain* is a mathematical model that exploits this property to predict the next state of a system given only its current state. Despite its simplicity requiring no memory of past states, this approach can prove powerful across many applications like natural language processing or random walks.

![]({{ site.url }}{{ site.baseurl }}/images/Markov/MarkovChainStructure.png)<!-- -->
